{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59b21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 12:54:44.177506: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import random\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889faad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa69830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    words = nltk.word_tokenize(text)\n",
    "#     words = [ps.stem(word.lower()) for word in words if word.isalnum()]  # Apply stemming\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30486fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow(sentence, vocab):\n",
    "#     sentence_words = preprocess_text(sentence)\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [ps.stem(w.lower()) for w in words if w.isalnum()]\n",
    "    sentence_words = sorted(list(set(words)))\n",
    "    bow = [1 if word in sentence_words else 0 for word in vocab]\n",
    "    return np.array(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e89b3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/apple/Desktop/testing/intents.json\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2da93bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[]\n",
    "for intents in data[\"intents\"]:\n",
    "    for patterns in intents[\"patterns\"]:\n",
    "        words.extend(preprocess_text(patterns))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "902a7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = [ps.stem(w.lower()) for w in words if w.isalnum()]\n",
    "words = sorted(list(set(words)))\n",
    "words = np.asarray(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "10694e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'about', 'afternoon', 'aka', 'alien', 'anim', 'anyon',\n",
       "       'appreci', 'are', 'asdkjd', 'asl', 'avail', 'bake', 'banana',\n",
       "       'been', 'beethoven', 'berri', 'best', 'bizarr', 'bla', 'blorp',\n",
       "       'blue', 'boopiti', 'bop', 'bot', 'buy', 'bye', 'cake', 'can',\n",
       "       'capac', 'car', 'care', 'casablanca', 'cat', 'catch', 'cereal',\n",
       "       'choic', 'cloud', 'color', 'conspiraci', 'cost', 'could', 'd',\n",
       "       'daft', 'dealership', 'dee', 'detail', 'dingl', 'dinosaur',\n",
       "       'disappear', 'display', 'do', 'doe', 'dollar', 'dolphin', 'doodl',\n",
       "       'dream', 'engin', 'even', 'exist', 'fast', 'fastest', 'favorit',\n",
       "       'featur', 'find', 'fit', 'flame', 'flibberti', 'floo', 'for',\n",
       "       'fraz', 'frizzl', 'froo', 'fruit', 'get', 'give', 'gloobiti',\n",
       "       'gloop', 'go', 'good', 'goodby', 'greet', 'ha', 'happi', 'have',\n",
       "       'hello', 'help', 'here', 'hey', 'hi', 'higgledi', 'how', 'howdi',\n",
       "       'i', 'if', 'in', 'india', 'invent', 'is', 'it', 'jabber', 'jibber',\n",
       "       'juggl', 'knee', 'know', 'kreebl', 'later', 'latest', 'laugh',\n",
       "       'laundri', 'leav', 'lifesav', 'like', 'list', 'lot', 'love',\n",
       "       'make', 'mani', 'mar', 'marshmallow', 'max', 'maximum', 'me',\n",
       "       'mean', 'mileag', 'million', 'minist', 'model', 'moonlit', 'more',\n",
       "       'morn', 'most', 'much', 'my', 'narfl', 'need', 'new', 'news', 'of',\n",
       "       'off', 'on', 'one', 'option', 'out', 'owe', 'peac', 'penguin',\n",
       "       'piggledi', 'pizza', 'plonk', 'price', 'prime', 'problem', 'punk',\n",
       "       'purchas', 'quickli', 'reach', 's', 'sale', 'sandwich', 'say',\n",
       "       'sd', 'season', 'secret', 'see', 'sell', 'show', 'ska', 'sky',\n",
       "       'snarfl', 'sock', 'sold', 'solv', 'some', 'sonata', 'soon', 'soup',\n",
       "       'space', 'spaghetti', 'speak', 'spec', 'specif', 'speed',\n",
       "       'squiggl', 'stand', 'stereo', 'stock', 'stroke', 'sword', 'take',\n",
       "       'talk', 'tell', 'thank', 'the', 'theori', 'there', 'they', 'thi',\n",
       "       'time', 'to', 'top', 'train', 'travel', 'unicorn', 'up', 'want',\n",
       "       'way', 'we', 'what', 'where', 'whi', 'which', 'whirf', 'who',\n",
       "       'wiggl', 'with', 'wobbl', 'womp', 'would', 'ya', 'yo', 'you',\n",
       "       'your', 'zangl', 'zingl'], dtype='<U11')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4be24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for intents in data[\"intents\"]:\n",
    "    for patterns in intents[\"patterns\"]:\n",
    "        X.append(create_bow(patterns,words))\n",
    "        y.append(intents[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ff69c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c18cffc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['greeting', 'greeting', 'greeting', 'greeting', 'greeting',\n",
       "       'greeting', 'greeting', 'greeting', 'greeting', 'greeting',\n",
       "       'greeting', 'greeting', 'greeting', 'greeting', 'greeting',\n",
       "       'greeting', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye',\n",
       "       'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye',\n",
       "       'thanks', 'thanks', 'thanks', 'thanks', 'thanks', 'thanks',\n",
       "       'thanks', 'thanks', 'thanks', 'thanks', 'show_cars', 'show_cars',\n",
       "       'show_cars', 'show_cars', 'show_cars', 'show_cars', 'show_cars',\n",
       "       'show_cars', 'show_cars', 'show_cars', 'buy_car', 'buy_car',\n",
       "       'buy_car', 'buy_car', 'buy_car', 'buy_car', 'buy_car', 'buy_car',\n",
       "       'buy_car', 'buy_car', 'car_price', 'car_price', 'car_price',\n",
       "       'car_price', 'car_price', 'car_price', 'car_price', 'car_price',\n",
       "       'car_price', 'car_details', 'car_details', 'car_details',\n",
       "       'car_details', 'car_details', 'car_details', 'car_details',\n",
       "       'car_details', 'car_details', 'car_details', 'car_speed',\n",
       "       'car_speed', 'car_speed', 'car_speed', 'car_speed', 'car_speed',\n",
       "       'car_speed', 'car_speed', 'car_speed', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage', 'garbage',\n",
       "       'garbage', 'garbage', 'garbage', 'garbage', 'garbage'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98c13a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['greeting','goodbye','thanks','show_cars','buy_car','car_price','car_details','car_speed','garbage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a580ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=[]\n",
    "for word in y:\n",
    "    enc = [1 if w in word else 0 for w in classes]\n",
    "    Y.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91fcc301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 9)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bc1581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 225)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7164e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,shuffle=True,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf91d1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 225)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04e26b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 9)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fd90750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 2.2156 - accuracy: 0.1339 \n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0959 - accuracy: 0.3125\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.0000 - accuracy: 0.3661\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8973 - accuracy: 0.4107\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7773 - accuracy: 0.4018\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6996 - accuracy: 0.3929\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5827 - accuracy: 0.4196\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4990 - accuracy: 0.4464\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.3596 - accuracy: 0.5179\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.3284 - accuracy: 0.5268\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.2429 - accuracy: 0.5536\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.1478 - accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.5982\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9114 - accuracy: 0.6429\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8743 - accuracy: 0.7411\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.6964\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8109 - accuracy: 0.7411\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.7768\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.8214\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.8304\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.8393\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8839\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.9732\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.9107\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.9554\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.9196\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8929\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9464\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9375\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9643\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9821\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9732\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9643\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9554\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9732\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9821\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9821\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9821\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9911\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9911\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9911\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9821\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9732\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9821\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9821\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9821\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9911\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9821\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9911\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9911\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9911\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9732\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9911\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9821\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9911\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9911\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9911\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9911\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9911\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9911\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape=(len(X_train[0]),), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "#     keras.layers.Dense(32, activation='relu'),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "#     keras.layers.Dense(16, activation='relu'),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(y_train[0]), activation='softmax')  # Output layer matches number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e482f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://67bc872c-77c7-4032-97a4-4c4904742d40/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model2.h5']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model,'model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "48fecc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45b00c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe1c41ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = [ np.argmax(p) for p in pred]\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e0a2b6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2c8a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_car_name(user_input):\n",
    "    # Tokenize and lower the input\n",
    "    tokens = user_input.lower().split()\n",
    "    \n",
    "    # Check for matching tokens in known car names\n",
    "    for car in car_details:\n",
    "        car_tokens = car.split()\n",
    "        if all(token in tokens for token in car_tokens):\n",
    "            return car\n",
    "    return None\n",
    "\n",
    "def get_car_details(car_name):\n",
    "    car_name = car_name.lower()\n",
    "    if car_name in car_details:\n",
    "        return car_details[car_name]\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "321c94df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla model s\n",
      "bmw 3 series\n",
      "audi a8\n",
      "mercedes-benz e-class\n",
      "ford mustang\n",
      "chevrolet corvette\n",
      "porsche 911\n",
      "honda civic\n",
      "toyota camry\n",
      "nissan gt-r\n",
      "lamborghini huracan\n",
      "ferrari 488\n",
      "mazda cx-5\n",
      "hyundai kona\n",
      "kia stinger\n"
     ]
    }
   ],
   "source": [
    "for car in car_details:\n",
    "    print(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "19bd5a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/apple/Desktop/testing/dataset.json\") as file:\n",
    "    car_details = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "da76173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(user_input):\n",
    "    # Tokenize and stem the user input\n",
    "    user_input = nltk.word_tokenize(user_input)\n",
    "    user_input = [ps.stem(word.lower()) for word in user_input]\n",
    "    \n",
    "    # Create a bag-of-words vector\n",
    "    bag = [0] * len(words)\n",
    "    for w in user_input:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array([bag])\n",
    "\n",
    "def classify_intent(user_input):\n",
    "    # Preprocess the input and predict the intent\n",
    "    bow = preprocess_input(user_input)\n",
    "    res = model.predict(bow)[0]\n",
    "    error_threshold = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > error_threshold]\n",
    "\n",
    "    # Sort by probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def get_response(intents_list, intents_json,user_input):\n",
    "    tag = intents_list[0][0]\n",
    "    intent_tag = classes[tag]\n",
    "    \n",
    "    # Find the corresponding intent and select a random response\n",
    "    if intent_tag == \"car_price\":\n",
    "        car = extract_car_name(user_input)\n",
    "        return random.choice(data['intents'][tag]['responses'])+car_details[car]['price']\n",
    "    elif intent_tag == \"buy_car\":\n",
    "        car = extract_car_name(user_input)\n",
    "        return random.choice(data['intents'][tag]['responses'])+car_details[car]['location']\n",
    "    elif intent_tag == \"car_details\":\n",
    "        car = extract_car_name(user_input)\n",
    "        return random.choice(data['intents'][tag]['responses'])+car_details[car]['details']\n",
    "    elif intent_tag == \"car_speed\":\n",
    "        car = extract_car_name(user_input)\n",
    "        return random.choice(data['intents'][tag]['responses'])+car_details[car]['speed']\n",
    "    elif intent_tag == \"garbage\":\n",
    "#         car = extract_car_name(user_input)\n",
    "        return random.choice(data['intents'][tag]['responses'])\n",
    "    elif intent_tag == \"show_cars\":\n",
    "        detail = \"\"\n",
    "        for car in car_details:\n",
    "            detail+=car+\"\\n\"\n",
    "        return detail\n",
    "    \n",
    "        \n",
    "        \n",
    "    for intent in intents_json['intents']:\n",
    "        if intent['tag'] == intent_tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    intents_list = classify_intent(user_input)\n",
    "    response = get_response(intents_list, data,user_input)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df0c5780",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintents\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[43mtag\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag' is not defined"
     ]
    }
   ],
   "source": [
    "data['intents'][tag]['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c958615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla model s\n",
      "bmw 3 series\n",
      "audi a8\n",
      "mercedes-benz e-class\n",
      "ford mustang\n",
      "chevrolet corvette\n",
      "porsche 911\n",
      "honda civic\n",
      "toyota camry\n",
      "nissan gt-r\n",
      "lamborghini huracan\n",
      "ferrari 488\n",
      "mazda cx-5\n",
      "hyundai kona\n",
      "kia stinger\n"
     ]
    }
   ],
   "source": [
    "for car in car_details:\n",
    "    print(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4a1379b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is running! Type 'quit' to exit.\n",
      "You: show me some cars;\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Bot: tesla model s\n",
      "bmw 3 series\n",
      "audi a8\n",
      "mercedes-benz e-class\n",
      "ford mustang\n",
      "chevrolet corvette\n",
      "porsche 911\n",
      "honda civic\n",
      "toyota camry\n",
      "nissan gt-r\n",
      "lamborghini huracan\n",
      "ferrari 488\n",
      "mazda cx-5\n",
      "hyundai kona\n",
      "kia stinger\n",
      "\n",
      "You: what is the price of Mazda cx-5\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Bot: This car is priced at $26,700\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is running! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    response = chatbot_response(user_input)\n",
    "    print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7254bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 0.99988866]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents_list = classify_intent(\"show me some cars\")\n",
    "intents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3a161839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'show_cars'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b4e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee49524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035b166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed85dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678f5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba41db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb453fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c7470424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'is', 'of', 'speed', 'the', 'thi', 'top', 'what']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[]\n",
    "word_list = nltk.word_tokenize(\"what is the top speed of this car?\")\n",
    "words.extend(word_list)\n",
    "words = [stemmer.stem(w.lower()) for w in words if w.isalnum()]\n",
    "words = sorted(list(set(words)))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6b79504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['about', 'appreci', 'buy', 'bye', 'can', 'car', 'cost', 'detail', 'do', 'doe', 'even', 'fast', 'give', 'good', 'goodby', 'have', 'hello', 'hey', 'hi', 'how', 'i', 'is', 'it', 'later', 'list', 'me', 'more', 'morn', 'much', 'of', 'price', 'purchas', 's', 'see', 'show', 'some', 'specif', 'speed', 'tell', 'thank', 'the', 'thi', 'top', 'what', 'where', 'you']\n",
      "Classes: ['buy_car', 'car_details', 'car_price', 'car_speed', 'goodbye', 'greeting', 'show_cars', 'thanks']\n",
      "Training Data: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Initialize lists for storing training data\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "\n",
    "# Loop through each intent in the JSON file\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # Tokenize each word in the sentence\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "        # Add to documents with its associated tag (intent)\n",
    "        documents.append((word_list, intent['tag']))\n",
    "        \n",
    "    # Add intent to the classes list\n",
    "    if intent['tag'] not in classes:\n",
    "        classes.append(intent['tag'])\n",
    "\n",
    "# Stem and lower each word, and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w.isalnum()]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(f\"Words: {words}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# Prepare training data\n",
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# Create bag-of-words for each pattern\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    \n",
    "    # Create the bag-of-words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    # Output is a one-hot encoded list for each intent\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# Shuffle the data and convert it into numpy arrays\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "# Split the features (X) and labels (y)\n",
    "X_train = np.array(list(training[:, 0]))\n",
    "y_train = np.array(list(training[:, 1]))\n",
    "\n",
    "print(f\"Training Data: {X_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb0b0f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[0.043018   0.03909636 0.01554782 0.05664859 0.22830929 0.6123372\n",
      "  0.00238561 0.00265713]]\n",
      "[[0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train[3:4]))\n",
    "print(y_train[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "241f1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_train[3:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "565b0865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 46)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a69cc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1192 - accuracy: 0.0769\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.0634 - accuracy: 0.1538\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0334 - accuracy: 0.0769\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.0045 - accuracy: 0.3846\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9827 - accuracy: 0.2308\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.9956 - accuracy: 0.1154\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.0095 - accuracy: 0.1538\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.0053 - accuracy: 0.0769\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.9894 - accuracy: 0.1154\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8524 - accuracy: 0.3846\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8022 - accuracy: 0.3846\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8961 - accuracy: 0.2308\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8433 - accuracy: 0.4615\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.8186 - accuracy: 0.3846\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7884 - accuracy: 0.4231\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6760 - accuracy: 0.6154\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6260 - accuracy: 0.5385\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5458 - accuracy: 0.5769\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5637 - accuracy: 0.5769\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6327 - accuracy: 0.4615\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4109 - accuracy: 0.7308\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5549 - accuracy: 0.5385\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4469 - accuracy: 0.6154\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3721 - accuracy: 0.6154\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.7308\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2489 - accuracy: 0.7308\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.2534 - accuracy: 0.8462\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1643 - accuracy: 0.8462\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2405 - accuracy: 0.6923\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4725 - accuracy: 0.5769\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0764 - accuracy: 0.8462\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0820 - accuracy: 0.7692\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.0229 - accuracy: 0.8462\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0758 - accuracy: 0.7692\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1750 - accuracy: 0.6923\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9129 - accuracy: 0.8077\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9506 - accuracy: 0.8846\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8533 - accuracy: 0.8077\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.8846\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9260 - accuracy: 0.8462\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.8880 - accuracy: 0.9231\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9731 - accuracy: 0.7308\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.8077\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7403 - accuracy: 0.8077\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.8846\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.9231\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.9615\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.9231\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.9231\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.8846\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.8462\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.9231\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.8462\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.9231\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8846\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.9615\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.9615\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.9615\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.9615\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.9231\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.9615\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.9231\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.9615\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.9615\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9615\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2119 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9615\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9615\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.9231\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9615\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1507 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9615\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9615\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9615\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9615\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9615\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.9615\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.9615\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9615\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9615\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9615\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0981 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9231\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9615\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9615\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9615\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9615\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9615\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9615\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9615\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9615\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9615\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9231\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9615\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9615\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9615\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9615\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9615\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9615\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape=(len(X_train[0]),), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(y_train[0]), activation='softmax')  # Output layer matches number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23967422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(user_input):\n",
    "    # Tokenize and stem the user input\n",
    "    user_input = nltk.word_tokenize(user_input)\n",
    "    user_input = [ps.stem(word.lower()) for word in user_input]\n",
    "    \n",
    "    # Create a bag-of-words vector\n",
    "    bag = [0] * len(words)\n",
    "    for w in user_input:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == w:\n",
    "                bag[i] = 1\n",
    "    return np.array([bag])\n",
    "\n",
    "def classify_intent(user_input):\n",
    "    # Preprocess the input and predict the intent\n",
    "    bow = preprocess_input(user_input)\n",
    "    res = model.predict(bow)[0]\n",
    "    error_threshold = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > error_threshold]\n",
    "\n",
    "    # Sort by probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def get_response(intents_list, intents_json):\n",
    "    tag = intents_list[0][0]\n",
    "    intent_tag = classes[tag]\n",
    "    \n",
    "    # Find the corresponding intent and select a random response\n",
    "    for intent in intents_json['intents']:\n",
    "        if intent['tag'] == intent_tag:\n",
    "            return random.choice(intent['responses'])\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    intents_list = classify_intent(user_input)\n",
    "    response = get_response(intents_list, data)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f64b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is running! Type 'quit' to exit.\n",
      "You: what\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Bot: Hello! How can I assist you today?\n",
      "You: huh\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Bot: Hi there! What car would you like to know about?\n",
      "You: lamborghini\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Bot: Hi there! What car would you like to know about?\n",
      "You: I want to see some cars today\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Bot: Here are a few options: [list of car names]. Which one would you like more details on?\n",
      "You: choose one for me\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Bot: This car has a speed of [speed], costs [price], and is available at [location]. Would you like to know more?\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is running! Type 'quit' to exit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    response = chatbot_response(user_input)\n",
    "    print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb029bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5dd717cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Example dataset of intents and BoW vectors\n",
    "# X = [...]  # List of BoW vectors\n",
    "# y = [...]  # Corresponding intent labels\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train a simple MLP classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(8, 8), max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Test the classifier\n",
    "accuracy = classifier.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30be62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b77bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fbc70074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 2.1152 - accuracy: 0.0500\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0811 - accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0484 - accuracy: 0.1500\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0173 - accuracy: 0.2000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9873 - accuracy: 0.3500\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9582 - accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9301 - accuracy: 0.4500\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9029 - accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8760 - accuracy: 0.7000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.8490 - accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8222 - accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7955 - accuracy: 0.8000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7687 - accuracy: 0.8500\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7419 - accuracy: 0.8500\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7150 - accuracy: 0.9000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6878 - accuracy: 0.9000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6598 - accuracy: 0.9000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6313 - accuracy: 0.9500\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6023 - accuracy: 0.9500\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5729 - accuracy: 0.9500\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5429 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5124 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4816 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4504 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4187 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3868 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3544 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3219 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2893 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2566 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2239 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1911 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1584 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1259 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0936 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0614 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0294 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9976 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9661 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9348 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9038 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8731 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8426 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8124 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7826 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7532 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3f71a2c80>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Train a simple MLP classifier\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(46,)),\n",
    "    keras.layers.Dense(128,activation=\"relu\"),\n",
    "    keras.layers.Dense(64,activation=\"relu\"),\n",
    "#     keras.layers.Dense(32,activation=\"relu\"),\n",
    "    keras.layers.Dense(8,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Test the classifier\n",
    "model.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "72085fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5ea55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
